{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, countDistinct\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import pyspark\n",
    "import time\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():        \n",
    "    return pyspark.sql.SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"RoadTracker\") \\\n",
    "        .getOrCreate() \\\n",
    "        .read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:redshift://roadtracker.cqgyzrqagvgs.us-east-1.redshift.amazonaws.com:5439/road-tracker?user=admin&password=roadTracker1\") \\\n",
    "        .option(\"dbtable\", \"vasco\") \\\n",
    "        .option(\"tempdir\", \"s3n://path/for/temp/data\")\n",
    "\n",
    "def init_mongo():\n",
    "    #use local\n",
    "    mongo_conn = \"mongodb://127.0.0.1\"\n",
    "    conf = SparkConf().set(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.1.1\")\n",
    "    conf.set(\"spark.write.connection.uri\", mongo_conn)\n",
    "    conf.set(\"spark.mongodb.write.database\", \"roadtracker\")\n",
    "    conf.set(\"spark.mongodb.write.collection\", \"collisionRisk\")\n",
    "    \n",
    "    sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "    return SparkSession(sc) \\\n",
    "        .builder \\\n",
    "        .appName(\"RoadTracker\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = init_spark()\n",
    "\n",
    "LastTimestamp = 0\n",
    "\n",
    "# back in time (1 minute)\n",
    "backInTime = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[road_id: string, speed_limit: int, road_size: int, x: int, y: int, plate: string, timestamp: string, direction: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFull = spark.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LimitTime: -60\n",
      "Time to filter: 0.009002685546875\n",
      "Time to window: 0.02000284194946289\n",
      "Time to filter: 0.03508496284484863\n",
      "Time to speed and acc: 0.09600234031677246\n",
      "Time to collision risk: 0.16900062561035156\n",
      "Time to analysis 6: 0.19299912452697754\n"
     ]
    }
   ],
   "source": [
    "# speed_limit as speed_limit \n",
    "dfFull = dfFull.withColumnRenamed(\"road_id\", \"road\")\n",
    "\n",
    "dfFull = dfFull.withColumn(\"time\", F.col(\"timestamp\").cast(\"float\"))\n",
    "dfFull = dfFull.withColumn(\"x\", F.col(\"x\").cast(\"int\"))\n",
    "dfFull = dfFull.withColumn(\"y\", F.col(\"y\").cast(\"smallint\"))\n",
    "dfFull = dfFull.withColumn(\"road_speed\", F.col(\"speed_limit\").cast(\"int\"))\n",
    "dfFull = dfFull.withColumn(\"direction\", F.col(\"direction\").cast(\"smallint\"))\n",
    "dfFull = dfFull.withColumn(\"road_size\", F.col(\"road_size\").cast(\"int\"))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# limit time to 1 minute before the last timestamp\n",
    "LimitTime = LastTimestamp - backInTime\n",
    "print(f'LimitTime: {LimitTime}')\n",
    "\n",
    "# Filter the records until 1 minute before the last timestamp\n",
    "dfNew = dfFull.filter(F.col(\"timestamp\") > LimitTime)\n",
    "\n",
    "print(f'Time to filter: {time.time() - start_time}')\n",
    "\n",
    "# get distinct plates\n",
    "# plates = dfNew.select(\"plate\").distinct()\n",
    "\n",
    "# # get the last 3 records of each car in plates from dfFull\n",
    "# dfNewRoad = dfFull.join(plates, \"plate\", \"inner\")\n",
    "\n",
    "windowDept = Window.partitionBy(\"plate\")\\\n",
    "    .orderBy(col(\"time\").desc())\n",
    "\n",
    "print(f'Time to window: {time.time() - start_time}')\n",
    "\n",
    "# get the last 3 records of each car\n",
    "dfNew = dfNew.withColumn(\"row\", row_number().over(windowDept)) \\\n",
    "    .filter(col(\"row\") <= 3)\n",
    "\n",
    "print(f'Time to filter: {time.time() - start_time}')\n",
    "\n",
    "# print(f'Size of batch: {dfNew.count()}')\n",
    "\n",
    "# ############################################\n",
    "# --------------- BASE ANALYSIS --------------\n",
    "# ############################################\n",
    "\n",
    "# -----------------------\n",
    "# VELOCIDADE E ACELERACAO\n",
    "\n",
    "# calculo da velocidade\n",
    "df = dfNew.withColumn(\"speed\", F.col(\"x\") - F.lag(\"x\", -1).over(windowDept))\n",
    "# make all values positive\n",
    "df = df.withColumn(\"speed\", F.abs(F.col(\"speed\")))\n",
    "# calculo da aceleracao\n",
    "df = df.withColumn(\"acc\", F.col(\"speed\") - F.lag(\"speed\", -1).over(windowDept))\n",
    "# drop null values\n",
    "df = df.na.drop()\n",
    "\n",
    "print(f'Time to speed and acc: {time.time() - start_time}')\n",
    "# -----------------------\n",
    "\n",
    "# -----------------------\n",
    "# DF DE RISCO DE COLISÃƒO\n",
    "windowDept = Window.partitionBy(\"road\", \"y\").orderBy(\"x\")\n",
    "# calcula o risco de colisao fazendo posicao + (velocidade * direcao) + (aceleracao * direcao)\n",
    "df = df.withColumn(\"collision_risk\",\n",
    "                    F.when(F.col(\"direction\") == 1,\n",
    "                            F.when((F.col(\"x\") + F.col(\"speed\") + F.col(\"acc\")) > (F.lag(\"x\", -1).over(windowDept) + F.lag(\"speed\", -1).over(windowDept) + F.lag(\"acc\",-1).over(windowDept)), 1).otherwise(0)) \\\n",
    "                    .otherwise(F.when((F.col(\"x\") - F.col(\"speed\") - F.col(\"acc\")) < (F.lag(\"x\", 1).over(windowDept) - F.lag(\"speed\", 1).over(windowDept) - F.lag(\"acc\", 1).over(windowDept)), 1).otherwise(0)))\n",
    "print(f'Time to collision risk: {time.time() - start_time}')\n",
    "# -----------------------\n",
    "\n",
    "# ----------------------- PRIORIDADE!\n",
    "# ANALISE 6: LISTA DE VEICULOS COM RISCO DE COLISAO\n",
    "# Placa e velocidade\n",
    "CollisionRisk = df.filter(F.col(\"collision_risk\") == 1) \\\n",
    "    .select(\"plate\", \"speed\")\n",
    "time_analysis6 = time.time() - start_time\n",
    "\n",
    "\n",
    "print(f'Time to analysis 6: {time_analysis6}')\n",
    "CollisionRisk.show()\n",
    "# CollisionRisk.write.format(\"mongodb\") \\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .option(\"database\", \"roadtracker\") \\\n",
    "#     .option(\"collection\", \"analysis6\") \\\n",
    "#     .save()\n",
    "    \n",
    "# -----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFull.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
